# AndesAI ğŸ”ï¸âœ¨

**AndesAI** Ã© uma extensÃ£o para Google Chrome que utiliza o poder de um modelo de linguagem rodando localmente para aprimorar, corrigir e "polir" textos diretamente em campos editÃ¡veis na web.

-----

### DemonstraÃ§Ã£o

![AndesAI Demo GIF](./demo.gif)

-----

## ğŸ“– Sobre o Projeto

Este projeto foi desenvolvido como uma aplicaÃ§Ã£o full-stack para demonstrar a integraÃ§Ã£o entre um frontend (extensÃ£o de navegador) e um backend de IA. A principal motivaÃ§Ã£o foi criar uma ferramenta de assistÃªncia de escrita que respeita a privacidade do usuÃ¡rio, processando todos os dados localmente, sem enviar informaÃ§Ãµes para servidores externos.

A extensÃ£o detecta de forma inteligente quando um usuÃ¡rio estÃ¡ em um campo de texto (`<textarea>` ou `contenteditable`), e, ao selecionar um trecho, apresenta uma UI flutuante para acionar a melhoria. O resultado Ã© entÃ£o apresentado em um modal com opÃ§Ãµes para substituir o texto original ou copiar o resultado.

-----

## âœ¨ Funcionalidades Principais

  * **IA Local:** Utiliza o modelo Llama 3.1 rodando via Ollama, garantindo que nenhum texto do usuÃ¡rio saia da sua mÃ¡quina.
  * **UI Contextual:** O botÃ£o "Improve" sÃ³ aparece em campos de texto editÃ¡veis, evitando poluir a interface em sites normais.
  * **Feedback Visual:** A interface informa ao usuÃ¡rio quando a IA estÃ¡ processando o texto atravÃ©s de um Ã­cone de carregamento (spinner).
  * **Modal de Resultados:** Exibe o texto original e o melhorado em um modal limpo e moderno.
  * **AÃ§Ãµes RÃ¡pidas:** BotÃµes para **Substituir** o texto original na pÃ¡gina ou **Copiar** o texto aprimorado para a Ã¡rea de transferÃªncia.
  * **ManipulaÃ§Ã£o Inteligente do DOM:** A funÃ§Ã£o de "Substituir" trata `<textarea>` e `contenteditable` de formas diferentes para garantir a integridade da pÃ¡gina.

-----

## ğŸ› ï¸ Tecnologias Utilizadas

  * **Backend:** Python, Flask, Flask-CORS
  * **InteligÃªncia Artificial:** Llama 3.1 8B, Ollama
  * **Frontend:** JavaScript (Vanilla JS), HTML5, CSS3
  * **Ambiente:** ExtensÃ£o de Navegador (Chrome Manifest V3)

-----

## ğŸ“‚ Estrutura do Projeto

```
AndesAI/
â”œâ”€â”€ extension/            # ContÃ©m os arquivos do frontend (extensÃ£o)
â”‚   â”œâ”€â”€ content.js
â”‚   â”œâ”€â”€ style.css
â”‚   â”œâ”€â”€ manifest.json
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ images/
â”‚       â””â”€â”€ ...
â””â”€â”€ server/               # ContÃ©m os arquivos do backend (servidor)
    â”œâ”€â”€ server.py
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ .venv/
```

-----

## ğŸš€ Como Instalar e Rodar

Siga os passos abaixo para ter o projeto rodando em sua mÃ¡quina.

### PrÃ©-requisitos

  * **Python 3.8+**: download em [python.com](https://www.python.org/downloads/)
  * **Ollama:** FaÃ§a o download em [ollama.com](https://ollama.com/)
  * **Git** (para clonar o repositÃ³rio) - [download](https://git-scm.com/downloads)

### 1. Backend (Servidor Python)

Primeiro, vamos configurar e iniciar o servidor local.

```bash
# 1. Clone este repositÃ³rio
git clone https://github.com/seu-usuario/AndesAI.git
cd AndesAI/server

# 2. Crie e ative um ambiente virtual
# No Windows
python -m venv venv
.\venv\Scripts\activate
# No macOS / Linux
python3 -m venv venv
source venv/bin/activate

# 3. Instale as dependÃªncias do Python
pip install -r requirements.txt

# 4. Baixe o modelo Llama 3.1 via Ollama (pode demorar um pouco)
ollama run llama3.1:8b

# 5. Inicie o servidor Flask (mantenha este terminal aberto)
python server.py
```

Se tudo deu certo, vocÃª verÃ¡ uma mensagem indicando que o servidor estÃ¡ rodando em `http://127.0.0.1:5000`.

### 2. Frontend (ExtensÃ£o do Chrome)

Agora, vamos carregar a extensÃ£o no seu navegador.

1.  Abra o Google Chrome.
2.  Navegue atÃ© `chrome://extensions`.
3.  No canto superior direito, ative o **"Modo de desenvolvedor"** (Developer mode).
4.  Clique no botÃ£o **"Carregar sem compactaÃ§Ã£o"** (Load unpacked).
5.  Uma janela para selecionar uma pasta se abrirÃ¡. Navegue atÃ© a pasta do projeto e selecione a pasta `extension` (`AndesAI/extension`).
6.  Clique em "Selecionar pasta".

A extensÃ£o **AndesAI** deverÃ¡ aparecer na sua lista de extensÃµes, pronta para uso!

-----

## ğŸ’¡ Como Usar

1.  Com o servidor Python rodando, navegue para qualquer site que tenha uma caixa de texto (como a Ã¡rea de comentÃ¡rios do YouTube, um post no Reddit, etc.).
2.  Digite um texto.
3.  Selecione o texto que vocÃª digitou.
4.  O botÃ£o "Improve âœ¨" aparecerÃ¡ ao lado do seu cursor. Clique nele.
5.  Aguarde o processamento e use os botÃµes "Replace" ou "Copy" no modal que aparecerÃ¡.

Com certeza. Ã‰ uma observaÃ§Ã£o muito importante para quem for testar seu projeto. Adicionar essa nota no `README.md` mostra que vocÃª pensou nas diferentes configuraÃ§Ãµes e cenÃ¡rios de uso.

Aqui estÃ¡ uma seÃ§Ã£o que vocÃª pode copiar e colar diretamente no final da seÃ§Ã£o "Como Usar" ou "Tecnologias Utilizadas" do seu `README.md`.

---

### ğŸ’¡ Nota sobre Performance e Qualidade

Este projeto foi configurado por padrÃ£o para usar o modelo `llama3.1:8b`, que oferece um excelente equilÃ­brio entre velocidade e qualidade na maioria dos computadores modernos.

VocÃª pode facilmente experimentar outros modelos disponÃ­veis no Ollama para ajustar a experiÃªncia ao seu hardware:

* **Para maior qualidade:** Se vocÃª possui uma placa de vÃ­deo potente (ex: 16GB+ de VRAM), pode obter respostas mais precisas e sofisticadas usando um modelo maior como o `llama3:70b`. A desvantagem Ã© um tempo de resposta mais lento.
* **Para maior velocidade:** Se a resposta parecer lenta em sua mÃ¡quina, considere usar um modelo mais leve como o `phi3`. A resposta serÃ¡ quase instantÃ¢nea, com uma pequena troca na complexidade da sugestÃ£o.

Para alterar o modelo, simplesmente edite a linha `"model": "llama3.1:8b"` no arquivo `server/server.py` para o modelo de sua escolha.